{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = {}\n",
    "for filename in os.listdir(\"Dataset\"):\n",
    "    pic_paths = []\n",
    "    foldername = os.path.join('./Dataset/', filename)   \n",
    "    try:\n",
    "        for pic_path in os.listdir(foldername):\n",
    "            pic_path = os.path.join(foldername, pic_path)\n",
    "            pic_paths.append(pic_path)\n",
    "        data_dictionary[filename] = [pic_paths]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "data_dictionary\n",
    "emotion_pic_df = pd.DataFrame(data = data_dictionary, index = ['pics']).T\n",
    "\n",
    "#-------------------------\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "def facial_pt_extractor (pic_path):\n",
    "#     print(pic_path)\n",
    "    def rect_to_bb(rect):\n",
    "        x = rect.left()\n",
    "        y = rect.top()\n",
    "        w = rect.right() - x\n",
    "        h = rect.bottom() - y\n",
    "        return (x, y, w, h)\n",
    "\n",
    "    def shape_to_np(shape, dtype=\"int\"):\n",
    "        coords = np.zeros((68, 2), dtype=dtype)\n",
    "        for i in range(0, 68):\n",
    "            coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "        return coords\n",
    "\n",
    "\n",
    "    def resize(image, width=1200):\n",
    "        r = width * 1.0 / image.shape[1]\n",
    "        dim = (width, int(image.shape[0] * r))\n",
    "        resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "        return resized\n",
    "    \n",
    "    image = cv2.imread(pic_path)\n",
    "    image = resize(image, width=1200)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 1)\n",
    "    \n",
    "    coordinates = []\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = shape_to_np(shape)\n",
    "\n",
    "#         (x, y, w, h) = rect_to_bb(rect)\n",
    "#         cv2.rectan gle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "#         cv2.putText(image, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        for (x, y) in shape:\n",
    "            coordinates.append(x)\n",
    "            coordinates.append(y)\n",
    "        \n",
    "    return coordinates\n",
    "\n",
    "answer = emotion_pic_df['pics'].apply(lambda x: [facial_pt_extractor(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy       [[129, 440, 134, 568, 148, 691, 163, 824, 200,...\n",
       "surprise    [[124, 475, 143, 605, 172, 733, 195, 859, 222,...\n",
       "neutral     [[127, 493, 141, 609, 160, 721, 181, 838, 220,...\n",
       "anger       [[153, 470, 162, 586, 185, 697, 216, 807, 254,...\n",
       "disgust     [[146, 478, 160, 603, 183, 726, 210, 848, 247,...\n",
       "Name: pics, dtype: object"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appending_list(original, adding):\n",
    "    original_cp = original.copy()\n",
    "    original_cp.append(adding)\n",
    "    return original_cp\n",
    "\n",
    "\n",
    "with_emotion = answer.to_frame().apply(lambda x: [appending_list(i, x.name) for i in x['pics']], axis = 1)\n",
    "# answer.to_frame().apply(lambda x: x.name, axis = 1)\n",
    "# answer.to_frame().apply(lambda x: display(x['pics']), axis = 1)\n",
    "# answer.to_frame().iloc[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[129,\n",
       " 440,\n",
       " 134,\n",
       " 568,\n",
       " 148,\n",
       " 691,\n",
       " 163,\n",
       " 824,\n",
       " 200,\n",
       " 943,\n",
       " 265,\n",
       " 1050,\n",
       " 350,\n",
       " 1138,\n",
       " 455,\n",
       " 1203,\n",
       " 586,\n",
       " 1221,\n",
       " 718,\n",
       " 1209,\n",
       " 828,\n",
       " 1153,\n",
       " 920,\n",
       " 1067,\n",
       " 992,\n",
       " 964,\n",
       " 1037,\n",
       " 845,\n",
       " 1061,\n",
       " 713,\n",
       " 1083,\n",
       " 586,\n",
       " 1096,\n",
       " 451,\n",
       " 197,\n",
       " 383,\n",
       " 256,\n",
       " 328,\n",
       " 338,\n",
       " 312,\n",
       " 421,\n",
       " 330,\n",
       " 498,\n",
       " 371,\n",
       " 689,\n",
       " 385,\n",
       " 769,\n",
       " 351,\n",
       " 855,\n",
       " 338,\n",
       " 941,\n",
       " 357,\n",
       " 1008,\n",
       " 409,\n",
       " 587,\n",
       " 461,\n",
       " 583,\n",
       " 544,\n",
       " 579,\n",
       " 626,\n",
       " 574,\n",
       " 709,\n",
       " 485,\n",
       " 748,\n",
       " 531,\n",
       " 764,\n",
       " 579,\n",
       " 779,\n",
       " 632,\n",
       " 766,\n",
       " 681,\n",
       " 751,\n",
       " 301,\n",
       " 456,\n",
       " 354,\n",
       " 424,\n",
       " 417,\n",
       " 430,\n",
       " 473,\n",
       " 478,\n",
       " 410,\n",
       " 479,\n",
       " 347,\n",
       " 476,\n",
       " 720,\n",
       " 485,\n",
       " 779,\n",
       " 441,\n",
       " 841,\n",
       " 444,\n",
       " 894,\n",
       " 478,\n",
       " 841,\n",
       " 491,\n",
       " 780,\n",
       " 490,\n",
       " 382,\n",
       " 864,\n",
       " 457,\n",
       " 849,\n",
       " 536,\n",
       " 841,\n",
       " 585,\n",
       " 852,\n",
       " 638,\n",
       " 842,\n",
       " 723,\n",
       " 854,\n",
       " 803,\n",
       " 868,\n",
       " 727,\n",
       " 964,\n",
       " 641,\n",
       " 1010,\n",
       " 585,\n",
       " 1015,\n",
       " 530,\n",
       " 1007,\n",
       " 453,\n",
       " 963,\n",
       " 404,\n",
       " 873,\n",
       " 534,\n",
       " 877,\n",
       " 585,\n",
       " 883,\n",
       " 638,\n",
       " 879,\n",
       " 778,\n",
       " 875,\n",
       " 639,\n",
       " 954,\n",
       " 585,\n",
       " 961,\n",
       " 534,\n",
       " 952,\n",
       " 'happy']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_emotion.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in with_emotion.sum():\n",
    "    with open('emotions.csv', 'a',newline = '') as csvFile:\n",
    "        file_is_empty = os.stat('emotions.csv').st_size == 0\n",
    "        writer = csv.writer(csvFile)\n",
    "        if file_is_empty:\n",
    "            writer.writerow([]*137)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy       [[129, 440, 134, 568, 148, 691, 163, 824, 200,...\n",
       "surprise    [[124, 475, 143, 605, 172, 733, 195, 859, 222,...\n",
       "neutral     [[127, 493, 141, 609, 160, 721, 181, 838, 220,...\n",
       "anger       [[153, 470, 162, 586, 185, 697, 216, 807, 254,...\n",
       "disgust     [[146, 478, 160, 603, 183, 726, 210, 848, 247,...\n",
       "Name: pics, dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-217-e20f0f0129b6>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-217-e20f0f0129b6>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    a.copy)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
